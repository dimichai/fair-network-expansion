{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'static_size': 2, 'dynamic_size': 1, 'num_layers': 1, 'dropout': 0.1, 'seed': None, 'checkpoint': None, 'test': False, 'epoch_max': 10, 'train_size': 128, 'line_unit_price': 1.0, 'station_price': 5.0, 'result_path': None, 'actor_lr': 0.001, 'critic_lr': 0.001, 'actor_mlp_layers': 5, 'critic_mlp_layers': 4, 'station_num_lim': 45, 'budget': 210, 'max_grad_norm': 2.0, 'environment': 'diagonal_5x5', 'reward': 'weighted', 'ses_weight': 0, 'var_lambda': 0, 'groups_file': None, 'arch': 'pointer'}\n",
      "No groups file provided. Trying to use the default groups file.\n"
     ]
    }
   ],
   "source": [
    "from environment import Environment\n",
    "from constraints import ForwardConstraints\n",
    "from trainer import Trainer\n",
    "from pathlib import Path\n",
    "from main import set_seed\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from typing import Callable\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Get cmd line arguments to reconstruct model\n",
    "result_path = \"result/diagonal_5x5_20220718_17_39_28.988157\"\n",
    "with open(os.path.join(result_path, \"args.txt\"), \"r\") as f:\n",
    "    args_dict = json.loads(f.read())\n",
    "args = argparse.Namespace(**args_dict)\n",
    "print(args_dict)\n",
    "\n",
    "environment = environment = Environment(Path(f\"./environments/{args.environment}\"), groups_file=args.groups_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No groups file provided. Trying to use the default groups file.\n",
      "Number of trainable parameters actor-critic: 182912 / 139181\n"
     ]
    }
   ],
   "source": [
    "# Load environment, constraints, and trainer\n",
    "if args.seed:\n",
    "    set_seed(args.seed)\n",
    "environment = Environment(Path(f\"./environments/{args.environment}\"), groups_file=args.groups_file)\n",
    "constraints = ForwardConstraints(environment.grid_x_size, environment.grid_y_size, environment.existing_lines_full, environment.grid_to_vector)\n",
    "trainer = Trainer(environment, constraints, args)\n",
    "trainer.load_checkpoint(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lo/git/fair-network-expansion/environment.py:58: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  grid_x = (vector_idx // self.grid_y_size)\n"
     ]
    }
   ],
   "source": [
    "static = environment.static.to(device)\n",
    "dynamic = torch.zeros((1, args.dynamic_size, environment.grid_size)).float().to(device)\n",
    "\n",
    "tour_idx = trainer.actor(static, dynamic, args.station_num_lim, budget=args.budget,\n",
    "                                                 line_unit_price=args.line_unit_price, station_price=args.station_price,\n",
    "                                                 decoder_input=None, last_hh=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[24, 12,  2,  1,  0]]), tensor([[-3.2430e+00, -2.0702e+00, -2.0905e+00, -6.9951e-01, -1.1921e-07]],\n",
      "       grad_fn=<CatBackward0>))\n",
      "torch.Size([25, 25])\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.7071, 0.7454, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.8284, 0.8579, 0.9262, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lo/git/fair-network-expansion/environment.py:58: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  grid_x = (vector_idx // self.grid_y_size)\n"
     ]
    }
   ],
   "source": [
    "fn1 = lambda d_eucl, d_tour: torch.nn.functional.relu(d_eucl/d_tour)\n",
    "fn2 = lambda d_eucl, d_tour: torch.nn.functional.relu(1 - ((d_tour-1)/d_eucl))\n",
    "\n",
    "def matrix_reward_scaling(tour_idx: torch.Tensor, environment: Environment, scaling_fn: Callable):\n",
    "    tour_idx = tour_idx[0].flatten()\n",
    "    tour_dict = {(s1, s2): tour_idx[i:j+1] for i, s1 in enumerate(tour_idx) for j, s2 in enumerate(tour_idx) if i != j and i < j}\n",
    "    od_scaling_mask = torch.zeros(environment.grid_size, environment.grid_size, device=device)\n",
    "\n",
    "    for c, subtour in tour_dict.items():\n",
    "        # Calculate direct euclidian distance\n",
    "        p1 = environment.vector_to_grid(c[0]).float()\n",
    "        p2 = environment.vector_to_grid(c[1]).float()\n",
    "        d_eucl = torch.dist(p1, p2, p=2)\n",
    "\n",
    "        # Calculate distance via subtour\n",
    "        points = [environment.vector_to_grid(p).float() for p in subtour]\n",
    "        d_tour = sum([torch.dist(points[i], points[i+1]) for i, _ in enumerate(points) if i != len(points) - 1])\n",
    "\n",
    "        # Calculate scaling factor for subtour connection\n",
    "        scaled = scaling_fn(d_eucl, d_tour)\n",
    "        od_scaling_mask[c[0], c[1]] = scaled\n",
    "        \n",
    "    \n",
    "    return od_scaling_mask\n",
    "    \n",
    "print(tour_idx)\n",
    "print(matrix_reward_scaling(tour_idx, environment, fn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.), tensor(1.)) tensor([0., 1.])\n",
      "(tensor(0.), tensor(2.)) tensor([0., 1., 2.])\n",
      "(tensor(0.), tensor(3.)) tensor([0., 1., 2., 3.])\n",
      "(tensor(0.), tensor(4.)) tensor([0., 1., 2., 3., 4.])\n",
      "(tensor(1.), tensor(2.)) tensor([1., 2.])\n",
      "(tensor(1.), tensor(3.)) tensor([1., 2., 3.])\n",
      "(tensor(1.), tensor(4.)) tensor([1., 2., 3., 4.])\n",
      "(tensor(2.), tensor(3.)) tensor([2., 3.])\n",
      "(tensor(2.), tensor(4.)) tensor([2., 3., 4.])\n",
      "(tensor(3.), tensor(4.)) tensor([3., 4.])\n",
      "{(tensor(0.), tensor(1.)): tensor([0., 1.]), (tensor(0.), tensor(2.)): tensor([0., 1., 2.]), (tensor(0.), tensor(3.)): tensor([0., 1., 2., 3.]), (tensor(0.), tensor(4.)): tensor([0., 1., 2., 3., 4.]), (tensor(1.), tensor(2.)): tensor([1., 2.]), (tensor(1.), tensor(3.)): tensor([1., 2., 3.]), (tensor(1.), tensor(4.)): tensor([1., 2., 3., 4.]), (tensor(2.), tensor(3.)): tensor([2., 3.]), (tensor(2.), tensor(4.)): tensor([2., 3., 4.]), (tensor(3.), tensor(4.)): tensor([3., 4.])}\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([0,1,2,3,4])\n",
    "tour_dict = {(s1, s2): a[i:j+1] for i, s1 in enumerate(a) for j, s2 in enumerate(a) if i != j and i < j}\n",
    "for i, s1 in enumerate(a):\n",
    "    for j, s2 in enumerate(a):\n",
    "        if i != j and i < j:\n",
    "            print((s1,s2), a[i:j+1])\n",
    "print(tour_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(3,3).byte()\n",
    "a[1,1] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.any(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('maskgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06f1d07516edbd9007e54bb291d9ebabb54455a8b1b4ee820873b558314f7277"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
